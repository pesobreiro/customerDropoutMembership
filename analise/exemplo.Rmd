---
title: |
  |
  |
  | \vspace{1cm}Literate programming with Python, R, Julia and Stata*^[*Corresponding address: miguel.portela@eeg.uminho.pt. The current template adapts part of the Rmd code by [Paul C. Bauer](https://github.com/paulcbauer/Writing_a_reproducable_paper_in_rmarkdown), Mannheim Centre for European Social Research.]\vspace{0.5cm}
  |
author: |
  | Pedro Sobreiro, Javier Berrocal, Domingos Martinho, Jos√© Garcia Alonso
  |
  | Extremadura University
  |
date: |
  |
  |
  | `r gsub("^0", "", format(Sys.time(), "%d %B, %Y"))`
  |
  |
linestretch: 1.2
colorlinks: true
abstract: \noindent\setstretch{1}Abstract of the article.\vspace{.8cm}
bibliography: references.bib
csl: american-sociological-association.csl
output:
  bookdown::pdf_document2:
    includes:
    toc: no
    keep_tex: true
    latex_engine: xelatex
mainfont: Times New Roman
sansfont: Times New Roman
fontsize: 12pt
link-citations: true
documentclass: article
geometry: margin=1in
always_allow_html: yes
header-includes:
   - \usepackage{dcolumn}
   - \usepackage{color}
   - \usepackage{pdfpages}
   - \usepackage{amsmath}
---


```{r Setup, include=FALSE}
   knitr::opts_chunk$set(cache = FALSE)
   # Use chache = TRUE if you want to speed up compilation
   
   # A function to allow for showing some of the inline code
   rinline <- function(code){
     html <- '<code  class="r">``` `r CODE` ```</code>'
     sub("CODE", code, html)

     ##https://opensource.com/article/19/5/python-3-default-mac

     ##Sys.setenv(RETICULATE_PYTHON = "C:/Users//AppData/Local/Microsoft/WindowsApps/python3")

   ##install.packages("reticulate")
   library(reticulate)
   ##use_python("/Library/Frameworks/Python.framework/Versions/3.8/bin/python3")

   ##use_virtualenv("C:/Users/mangelo.EEG/Documents/python")

   ##knitr::opts_chunk$set(python.reticulate=FALSE)

   # library(devtools) # before this you may need to install devtools
   # install_github("hemken/Statamarkdown")

   }
```

```{r RETICULATE,echo=FALSE}
#Sys.setenv(RETICULATE_PYTHON = "C:/Program Files/Python39/python.exe")
#library(reticulate)
#use_virtualenv("C:/Users/mangelo.EEG/Documents/python")
```



\clearpage

\renewcommand{\baselinestretch}{0.5}\normalsize
[//]: # \tableofcontents
\renewcommand{\baselinestretch}{1.1}\normalsize

\clearpage



```{r Stats, echo=TRUE, message=FALSE}
library(dplyr)
library(dlookr)
library(ggplot2)

##eda_report(nlswork,output_dir = "C:/Users/mangelo.EEG/Documents/GitHub/prjs/reports/",output_file = "eda_report.pdf")

## The data

names(airquality)
##summary(nlswork)

## Missing values

library(visdat)
vis_dat(airquality)


library(naniar)
vis_miss(airquality)

gg_miss_upset(airquality)
## GRAPHS
dplyr::glimpse(cars$Ozone)
d <- density(airquality$Temp)
plot(d)

plot(airquality$Ozone, airquality$Solar.R)
ggplot(airquality, aes(x = Ozone, y = Solar.R)) +
geom_miss_point()

ggplot(airquality, aes(x = Wind, y = Temp)) +
geom_miss_point() +
facet_wrap(vars(Month))

stats <- summary(airquality$Temp)
stats

describe(airquality)

```

The average age in our data is `r round(mean(nlswork$age,na.rm=TRUE),1)`.

# Tables {#sec:tables}
R Markdown PDF is now able to produce good tables with our output. For `stargazer` the label is contained in the function, while for `kable` it's contained in the chunk name.

## stargazer(): Summary and regression tables

Table \@ref(tab1) shows data's summary statistics.^[You can reference the table as \@ref(tab1cars).] `stargazer()` is and excellent solution to export outputs.


```{r Export Stats, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, results="asis"}
library(stargazer)
stargazer(cars,
          title = "Summary table with stargazer",
          label="tab1cars",
          table.placement = "H",
          header=FALSE)
```

Table \@ref(tab2) reports regression outputs. Name the models as you can refer to their names in the text (M1, M2, M3).

```{r Export Regressions, echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, results="asis"}
library(stargazer)
model1 <- lm(speed ~ dist, data = cars)
model2 <- lm(speed ~ dist, data = cars)
model3 <- lm(dist ~ speed, data = cars)
stargazer(model1, model2, model3,
          title = "Regression table with stargazer",
          label="tab2",
          table.placement = "H",
          column.labels = c("M1", "M2", "M3"),
          model.numbers = FALSE,
          header=FALSE)
```

# Figures

## Graphs with R
You can insert figures like this. One would like to produce and insert them on the fly in the `.rmd` file. Figure \@ref(fig:fig-1) is such an example.

```{r Figures 1, fig-1, fig.align="center", fig.cap="Scatterplot of Speed and Distance", fig.pos="H", message=FALSE, warning=FALSE, paged.print=FALSE}
plot(cars$speed, cars$dist)
```

However, in some cases it does not work.

## Example: ggplot2 graphs
See the `ggplot2` output reported in Figure \@ref(fig:fig-2).

```{r Fig-2, fig.align="center", fig.cap="Miles per gallon according to the weight", fig.pos="H", fig.width=6, fig.height=3, message=FALSE, warning=FALSE, paged.print=FALSE}
mtcars$cyl <- as.factor(mtcars$cyl) # Convert cyl to factor
library(ggplot2)
ggplot(mtcars, aes(x=wt, y=mpg, shape=cyl)) + geom_point() +
  labs(x="Weight (lb/1000)", y = "Miles/(US) gallon",
       shape="Number of \n Cylinders") + theme_classic()
```

## Another example using Plotly
With `Plotly` we can produce interactive graphs which play well, for example, once can embeded in html webpages (drop by  [here](https://paulcbauer.shinyapps.io/visualizing-causal-scenarios/) for an example). One can insert this type of graphs in R Markdown PDF using `Orca` (it generates static images from Plotly graphs). Go [here](https://github.com/plotly/orca#installation) to check how to install it. See Figure \@ref(fig:fig-3) for an example.

```{r Fig-3, message=FALSE, warning=FALSE}
library(plotly)
p <- plot_ly(cars, type = "scatter", mode="markers",
        x=~speed,
        y=~dist)
#Sys.setenv('MAPBOX_TOKEN' = '12423423') # set arbitrary token
#orca(p, "logs/plotly-plot.pdf")
```


\begin{figure}[ht]
\centering
\caption{Example: export a Plotly figure using `orca`}\label{fig:fig-3}
		\includegraphics[width=0.9\linewidth]{logs/plotly-plot.pdf}
\begin{flushleft}
\end{flushleft}
\end{figure}
\vspace{-1.2cm}



# Python

## API data download using Python

```{python Py,eval=TRUE,echo=TRUE}
import sys
print(sys.version)


import json
##from json.decoder import JSONDecodeError
import requests
import numpy as np
import pandas as pd

## INE: https://www.ine.pt/ine/json_indicador/pindica.jsp?
## op=2&varcd=0008074&Dim1=S7A2015&Dim2=200&Dim3=3&lang=PT

# api-endpoint

URL = "https://www.ine.pt/ine/json_indicador/pindica.jsp"

# define parameters

OP="2"
VARCD="0008074"
DIM1="S7A2015"
DIM2="200"
DIM3="3"
LANG="PT"


# defining a params dict for the parameters to be sent to the API
PARAMS = {'op':OP,'varcd':VARCD,'Dim1':DIM1,'Dim2':DIM2,'Dim3':DIM3,'lang':LANG}

# sending get request and saving the response as response object
r = requests.get(url = URL,params=PARAMS)

# extracting data in json format
data = r.json()

valor = data[0]['Dados']['2015'][0]['valor']

valor

```

The criminal rate is `r py$valor`\%o.

\vspace{0.3cm}

## Import data from PDF files

```{bash Bash,eval=FALSE}
  cd C:/Users/mangelo.EEG/Documents/GitHub/prjs/pdfs
	find . -name '*.pdf' -print0 | xargs -0 -n1 pdfsandwich -gray
	find . -name '*ocr.pdf' -print0 | xargs -0 -n1 pdftotext
```


```{python Python 2, eval=TRUE,echo=FALSE}
import os
import numpy as np
import pandas as pd
import re

## CHECK PyPDF2

## wget -A pdf -m -p -E -k -K -np https://joram.madeira.gov.pt/joram/4serie/
## find . -name '*.pdf' -print0 | xargs -0 -n1 pdfsandwich -gray
## find . -name '*ocr.pdf' -print0 | xargs -0 -n1 pdftotext

# Create list with .txt files for the specified folder
files_list = list()
for (dirpath, dirnames, filenames) in os.walk('C:/Users/mangelo.EEG/Documents/GitHub/prjs/pdfs/'):
    files_list += [os.path.join(dirpath, file)
                   for file in filenames if file.endswith('.txt')]


##print("START:FILES -- list")

##print(files_list)

##print("END:FILES -- list")

p1 = r'PORTARIA'
p2 = r'EXTENSAO'
p3 = r'Materiais'
p5 = r'PE das'

linha = []
output = []
other = []
palavra = []
source = []

for file in files_list:

    f = open(file, "r", encoding='latin8')
    data = f.read()
    f.close()

    line = []
    nh = 0

    tmp1 = str(data)
    #print(tmp1)
    tmp2 = tmp1.splitlines()
    #print(tmp2)
    for n,tmp3 in enumerate(tmp2):
        #print(tmp3)
        if (tmp3.find("PE das") == 0):
            tmp4 = tmp3 + tmp2[2]
            line.append(tmp4)
            #print(n)
            nh = 1
        elif (nh == 1):
            nh = 0
            continue
        elif (nh == 0):
            line.append(tmp3)

    print(line)

    print("   ")

    print("FILE: ", file[46:-4])

    for num, word in enumerate(line):
            if num == 0:
                continue
            else:
                match1 = re.search(p1, word)
                match2 = re.search(p2, word)
                match3 = re.search(p3, word)
                match4 = re.search(r'\d{9}', word)
                match5 = re.search(p5, word)
                ##print("   ")
                ##print("START: ",num)

                if match1:
                        ##print("   ")
                        print("match 1")
                        if match4:
                            ##print("   ")
                            print("match 4")
                            linha.append(num)
                            output.append(re.search(r'\d{9}', word).group())
                            other.append("vazio")
                            palavra.append(p1)
                            source.append(file[46:-4])
                elif match2:
                            ##print("   ")
                            print("match 2")
                            linha.append(num)
                            output.append(re.search(r'\d{9}', word).group())
                            other.append("vazio")
                            palavra.append(p2)
                            source.append(file[46:-4])
                elif match3:
                            ##print("   ")
                            print("match 3")
                            linha.append(num)
                            output.append(re.search(r'\d{9}', word).group())
                            other.append("vazio")
                            palavra.append(p3)
                            source.append(file[46:-4])
                elif match5:
                            ##print("   ")
                            print("-> match 5")
                            ##word.sub(" e o ", " e a ",1)
                            print(word)
                            linha.append(num)

                            if (word.find(" e o ") > 0):
                                print("11111")
                                output.append((word.split("re a", 1)[1]).split(" e o ", -1)[-2])
                                other.append((word.split("re a", 1)[1]).split(" e o ", 1)[1])
                            elif (word.find(" e a ") > 0):
                                print("99999")
                                output.append((word.split("re a", 1)[1]).split(" e a ", -1)[-2])
                                other.append((word.split("re a", 1)[1]).split(" e a ", 1)[1])

                            palavra.append(p5)
                            source.append(file[46:-4])
## o paragrafo tem de estar na mesma linha e temos de ter 'e a' em vez de 'e o'
df = pd.DataFrame({'linha': linha, 'output': output,
                   'outra': other, 'source': source})
print(df)

df.to_csv('data/PE.csv', index=False)
df.to_stata('data/PE.dta', write_index = False)

```




And now we use Stata to explore the data.

```{stata Stata Import CSV, echo=TRUE,message=FALSE}

quiet cd "C:/Users/mangelo.EEG/Documents/GitHub/prjs/logs"
quiet import delimited "C:/Users/mangelo.EEG/Documents/GitHub/prjs/data/PE.csv", encoding(ISO-8859-2) clear
tab source

```

## Run a Python script to read a PDF using the shell to run the commands wget, pdfsandwich and pdftotext

```{bash Bash 2}
python3 "C:/Users/mangelo.EEG/Documents/GitHub/prjs/chunks/python_chunk.py"
```

## Use Stata to list the fiscal numbers (read the data produced with Python)

```{stata Codebook, echo=TRUE,message=FALSE}

quietly{
cd C:/Users/mangelo.EEG/Documents/GitHub/prjs/chunks

use C:/Users/mangelo.EEG/Documents/GitHub/prjs/data/nipcs, clear
compress
contract nipc
drop _freq
drop if nipc == .
format %12.0f nipc
}

//codebook nipc

tab nipc
```

# Julia experiments

## Computations

```{julia Julia experiments, echo=FALSE}
## This is a julia language chunk.
## In julia, the command without ending semicolon will trigger the display
## so is JuliaCall package.
## The julia display will follow immediately after the corresponding command
## just as the R code in R Markdown.

using ReadStat
using StatFiles
using StatsBase
using DataFrames
using FixedEffectModels

@time results_hdfe1 = reg(DataFrame(load("C:/Users/mangelo.EEG/Documents/GitHub/prjs/data/data_short.dta")), @formula(lnrealwage ~ education + lnsales + fe(workerid) + fe(year)));

@time results_hdfe2 = reg(DataFrame(load("C:/Users/mangelo.EEG/Documents/GitHub/prjs/data/data_short.dta")), @formula(lnrealwage ~ education + lnsales + fe(workerid) + fe(firmid) + fe(year)));

using RegressionTables
regtable(results_hdfe1,results_hdfe2; renderSettings = latexOutput("logs/hdfe_output.tex"))

VERSION
```

## Grab results in R

```{r Grab results in R, echo=FALSE}
library(JuliaCall)

  julia_eval("results_hdfe2")

betas <- julia_eval("coef(results_hdfe2)")
r2 <- julia_eval("r2(results_hdfe2)")
```

## Insert Julia's results

\vspace{0.3cm}

The estimated return to education is `r round(betas[1:1]*100,1)`\%. The model has an $R^2$ of `r round(r2,4)`.

\vspace{0.3cm}

## Computation time: run the HDFE with Stata and R and compare to Julia

```{stata HDFE with Stata, echo=TRUE,message=FALSE}

use C:/Users/mangelo.EEG/Documents/GitHub/prjs/data/data_short, clear

timer on 1

	reghdfe lnrealwage education lnsales,absorb(workerid firmid year)

timer off 1
timer list 1
timer clear 1
```

```{r,eval=FALSE,echo=TRUE}
library(lfe)
data_short <- read_dta("C:/Users/mangelo.EEG/Documents/GitHub/prjs/data/data_short.dta")

system.time(est_hdfe <- felm(data_short$lnrealwage ~ data_short$education + data_short$lnsales | data_short$workerid + data_short$firmid + data_short$year))

summary(est_hdfe)
```


## Output Julia's table for HDFE

\begin{table}[ht]
\label{tab:hdfe}
  \input{logs/hdfe_output}
\end{table}


# Miguel's tests

## R

Table \@ref(tab3) ... See Section \@ref(sec:stata)

Example of an equation

$$\int_0^{2\pi} \sin x~dx$$

*Example of a matrix*


$$
\mathbf{X} = \left[\begin{array}
{rrr}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{array}\right]
$$

or

\begin{equation}
f\left(k\right)=\binom{n}{k}p^k\left(1-p\right)^{n-k} \label{eq:binom}
\end{equation}



See Equation \@ref(eq:binom).



\begin{align}
y_{ijt} = \beta x_{ijt} + \eta_i + \gamma_j + \lambda_t + \varepsilon_{ijt}
\end{align}



```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE, results="asis"}
library(stargazer)
library(Statamarkdown)
stataexe <- "C:/Program Files/Stata16/StataMP-64.exe"
knitr::opts_chunk$set(engine.path=list(stata=stataexe))

setwd("C:/Users/mangelo.EEG/Documents/GitHub/prjs/logs")
rm(list = ls())
library(haven)
nlswork <- read_dta("../data/nlswork.dta")

auto <- read_dta("../data/auto.dta")

attach(nlswork)

regs1 <- lm(auto$price ~ auto$mpg + auto$weight)
regs2 <- lm(auto$price ~ auto$mpg + auto$weight + auto$rep78)
regs3 <- lm(auto$price ~ auto$mpg + auto$weight + auto$rep78 + auto$trunk)

regs4 <- lm(ln_wage ~ union)
regs5 <- lm(ln_wage ~ union + collgrad)
regs6 <- lm(ln_wage ~ union + collgrad + age)

##summary(auto)
##summary(regs1)

## https://www.jakeruss.com/cheatsheets/stargazer/

nls<-data.frame(nlswork)

stargazer(nls, summary.stat = c("n", "p75", "sd"), summary.logical = FALSE,
          title = "Summary table",
          label="tab23",
          table.placement = "ht",
          header=FALSE)


stargazer(regs1, regs2, regs3,
          title = "Regression table with stargazer",
          label="tab3",
          table.placement = "ht",
          column.labels = c("M1", "M2", "M3"),
          model.numbers = FALSE,
          header=FALSE,keep=c(0,1,2,3))

attach(auto)


library(naniar)
vis_miss(nlswork)

# plot(y=price,x=mpg)

```



```{r echo=TRUE, message=FALSE, warning=FALSE, paged.print=FALSE, results="asis"}
library(stargazer)
stargazer(cars,
          title = "Summary 24",
          label="tab24",
          table.placement = "ht",
          header=FALSE)
```


## Grab Stata's output

\vspace{0.3cm}

The mean ln GDP is `r format(as.numeric(readLines('example.txt')), digits = 2)`.

\vspace{0.3cm}

```{r cleanup, include=FALSE} 
unlink("example.txt")
```

See https://www.ssc.wisc.edu/~hemken/Stataworkshops/stata.html#stata-and-r-markdown-the-statamarkdown-package

![Wage density](logs/density.pdf)


\begin{table}[ht]
\caption{Regression analysis}
\label{tab:stata}
  \input{logs/growth_analysis_frag}
\end{table}

## Use Stata to export statistics to Excel

We now export a set of statistics to an Excel file.

See Figure \@ref(fig:fig-tmp).

```{r fig-tmp, echo=FALSE, fig.align="center", fig.cap="Scatterplot test MP", fig.pos="ht", message=FALSE, warning=FALSE, paged.print=FALSE}
plot(x = mpg, y = price,
     pch = 16, frame = FALSE,
     xlab = "wt", ylab = "mpg", col = "#2E9FDF")
```


# Final remarks

Check the replication package for Bonhomme, Lamadon and Manresa (2019): https://github.com/tlamadon/blm-replicate

\newpage

# References {-}


<div id="refs"></div>


# Appendix: Chunk options {-}

## Software versioning

### R

```{r fig-versioning, echo=TRUE}
cat(paste("#", capture.output(sessionInfo()), "\n", collapse =""))
  # or use message() instead of cat()
```

### Python

```{python py2,eval=TRUE,echo=TRUE}
import sys
print(sys.version)
```

### Julia

```{julia echo=FALSE}
VERSION
```

## All the code in the paper

To simply attach all the code you used in the PDF file in the appendix see the R chunk in the underlying `.rmd` file:

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}
```

<!-- ## Exploratory data analysis report -->

<!-- [//]: # \includepdf[pages=-]{C:/Users/mangelo.EEG/Documents/GitHub/prjs/reports/eda_report.pdf} -->
